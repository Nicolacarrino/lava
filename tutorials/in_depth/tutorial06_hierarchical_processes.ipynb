{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df0639b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "*Copyright (C) 2021 Intel Corporation*<br>\n",
    "*SPDX-License-Identifier: BSD-3-Clause*<br>\n",
    "*See: https://spdx.org/licenses/*\n",
    "\n",
    "---\n",
    "\n",
    "# Hierarchical _Processes_ and _SubProcessModels_\n",
    "\n",
    "Previous tutorials have briefly covered that there are two categories of _ProcessModels_: _LeafProcessModels_ and _SubProcessModels_. The [ProcessModel Tutorial](./tutorial03_process_models.ipynb) explained _LeafProcessModels_ in detail. These implement the behavior of a _Process_ directly, in the language (for example, Python or Loihi Neurocore API) required for a particular compute resource (for example, a CPU or Loihi Neurocores). _SubProcessModels_, by contrast, allow users to implement and compose the behavior of a process _using other processes_. This enables the creation of _Hierarchical Processes_ and reuse of primitive _ProcessModels_ to realize more complex _ProcessModels_. _SubProcessModels_ inherit all compute resource requirements from the sub _Processes_ they instantiate. \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/lava-nc/lava-nc.github.io/main/_static/images/tutorial07/fig01_subprocessmodels.png\"/>\n",
    "\n",
    "In this tutorial, we will create a Dense Layer Hierarchical _Process_ that has the behavior of  Leaky-Integrate-and-Fire (LIF) neurons. The Dense Layer _ProcessModel_ implements this behavior via the primitive LIF and Dense Connection _Processes_ and their respective _PyLoihiProcessModels_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361b53f8-24da-4b60-93b5-ece9e05a7eca",
   "metadata": {},
   "source": [
    "## Recommended tutorials before starting: \n",
    "\n",
    "- [Installing Lava](./tutorial01_installing_lava.ipynb \"Tutorial on Installing Lava\")\n",
    "- [Processes](./tutorial02_processes.ipynb \"Tutorial on Processes\")\n",
    "- [ProcessModel](./tutorial03_process_models.ipynb \"Tutorial on ProcessModels\")\n",
    "- [Execution](./tutorial04_execution.ipynb \"Tutorial on Executing Processes\")\n",
    "- [Connecting Processes](./tutorial05_connect_processes.ipynb \"Tutorial on Connecting Processes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25486c95",
   "metadata": {},
   "source": [
    "## Create LIF and Dense _Processes_ and _ProcessModels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9dca97",
   "metadata": {},
   "source": [
    "The [ProcessModel Tutorial](#tutorial03_process_models.ipynb) walks through the creation of a LIF _Process_ and an implementing _PyLoihiProcessModel_. Our DenseLayer _Process_ also requires a Dense Lava _Process_ and _ProcessModel_ that have the behavior of a dense set of synaptic connections and weights. The Dense Connection _Process_ can be used to connect neural _Processes_. For completeness, we'll first briefly show an example LIF and Dense _Process_ and _PyLoihiProcessModel_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41d3af0",
   "metadata": {},
   "source": [
    "#### Create a Dense connection _Process_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c44a34ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lava.magma.core.process.process import AbstractProcess\n",
    "from lava.magma.core.process.variable import Var\n",
    "from lava.magma.core.process.ports.ports import InPort, OutPort\n",
    "\n",
    "\n",
    "class Dense(AbstractProcess):\n",
    "    \"\"\"Dense connections between neurons.\n",
    "    Realizes the following abstract behavior:\n",
    "    a_out = W * s_in\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        shape = kwargs.get(\"shape\", (1, 1))\n",
    "        self.s_in = InPort(shape=(shape[1],))\n",
    "        self.a_out = OutPort(shape=(shape[0],))\n",
    "        self.weights = Var(shape=shape, init=kwargs.pop(\"weights\", 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3388c481",
   "metadata": {},
   "source": [
    "#### Create a Python Dense connection _ProcessModel_ implementing the Loihi Sync Protocol and requiring a CPU compute resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf921be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-4f5fdbfeefd3>:17: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  a_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, np.float)\n",
      "<ipython-input-2-4f5fdbfeefd3>:18: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  weights: np.ndarray = LavaPyType(np.ndarray, np.float)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from lava.magma.core.sync.protocols.loihi_protocol import LoihiProtocol\n",
    "from lava.magma.core.model.py.ports import PyInPort, PyOutPort\n",
    "from lava.magma.core.model.py.type import LavaPyType\n",
    "from lava.magma.core.resources import CPU\n",
    "from lava.magma.core.decorator import implements, requires\n",
    "from lava.magma.core.model.py.model import PyLoihiProcessModel\n",
    "\n",
    "# from lava.proc.dense.process import Dense\n",
    "\n",
    "\n",
    "@implements(proc=Dense, protocol=LoihiProtocol)\n",
    "@requires(CPU)\n",
    "class PyDenseModel(PyLoihiProcessModel):\n",
    "    s_in: PyInPort = LavaPyType(PyInPort.VEC_DENSE, bool)\n",
    "    a_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, np.float)\n",
    "    weights: np.ndarray = LavaPyType(np.ndarray, np.float)\n",
    "\n",
    "    def run_spk(self):\n",
    "        s_in = self.s_in.recv()\n",
    "        a_out = self.weights[:, s_in].sum(axis=1)\n",
    "        self.a_out.send(a_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af429f49-0493-4096-a914-a9972f7c5fcb",
   "metadata": {},
   "source": [
    "#### Create a LIF neuron _Process_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f909ec9e-2d54-44e0-a095-d2ccc19506a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lava.magma.core.process.process import AbstractProcess\n",
    "from lava.magma.core.process.variable import Var\n",
    "from lava.magma.core.process.ports.ports import InPort, OutPort\n",
    "\n",
    "\n",
    "class LIF(AbstractProcess):\n",
    "    \"\"\"Leaky-Integrate-and-Fire (LIF) neural Process.\n",
    "    LIF dynamics abstracts to:\n",
    "    u[t] = u[t-1] * (1-du) + a_in         # neuron current\n",
    "    v[t] = v[t-1] * (1-dv) + u[t] + bias  # neuron voltage\n",
    "    s_out = v[t] > vth                    # spike if threshold is exceeded\n",
    "    v[t] = 0                              # reset at spike\n",
    "    Parameters\n",
    "    ----------\n",
    "    du: Inverse of decay time-constant for current decay.\n",
    "    dv: Inverse of decay time-constant for voltage decay.\n",
    "    bias: Neuron bias.\n",
    "    vth: Neuron threshold voltage, exceeding which, the neuron will spike.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        shape = kwargs.get(\"shape\", (1,))\n",
    "        du = kwargs.pop(\"du\", 0)\n",
    "        dv = kwargs.pop(\"dv\", 0)\n",
    "        bias = kwargs.pop(\"bias\", 0)\n",
    "        vth = kwargs.pop(\"vth\", 10)\n",
    "\n",
    "        self.shape = shape\n",
    "        self.a_in = InPort(shape=shape)\n",
    "        self.s_out = OutPort(shape=shape)\n",
    "        self.u = Var(shape=shape, init=0)\n",
    "        self.v = Var(shape=shape, init=0)\n",
    "        self.du = Var(shape=(1,), init=du)\n",
    "        self.dv = Var(shape=(1,), init=dv)\n",
    "        self.bias = Var(shape=shape, init=bias)\n",
    "        self.vth = Var(shape=(1,), init=vth)\n",
    "        # self.spikes = Var(shape=shape, init=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c58564f-9fd4-4560-ad53-d2ec4b7c52a5",
   "metadata": {},
   "source": [
    "#### Create a Python LIF neuron _ProcessModel_ implementing the Loihi Sync Protocol and requiring a CPU compute resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54b48aa4-a35a-496f-9b07-0dc41d03cb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-815180f30e4a>:15: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  a_in: PyInPort = LavaPyType(PyInPort.VEC_DENSE, np.float)\n",
      "<ipython-input-4-815180f30e4a>:17: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  u: np.ndarray = LavaPyType(np.ndarray, np.float)\n",
      "<ipython-input-4-815180f30e4a>:18: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  v: np.ndarray = LavaPyType(np.ndarray, np.float)\n",
      "<ipython-input-4-815180f30e4a>:19: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bias: np.ndarray = LavaPyType(np.ndarray, np.float)\n",
      "<ipython-input-4-815180f30e4a>:20: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  du: float = LavaPyType(float, np.float)\n",
      "<ipython-input-4-815180f30e4a>:21: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dv: float = LavaPyType(float, np.float)\n",
      "<ipython-input-4-815180f30e4a>:22: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  vth: float = LavaPyType(float, np.float)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from lava.magma.core.sync.protocols.loihi_protocol import LoihiProtocol\n",
    "from lava.magma.core.model.py.ports import PyInPort, PyOutPort\n",
    "from lava.magma.core.model.py.type import LavaPyType\n",
    "from lava.magma.core.resources import CPU\n",
    "from lava.magma.core.decorator import implements, requires\n",
    "from lava.magma.core.model.py.model import PyLoihiProcessModel\n",
    "\n",
    "# from lava.proc.lif.process import LIF\n",
    "\n",
    "\n",
    "@implements(proc=LIF, protocol=LoihiProtocol)\n",
    "@requires(CPU)\n",
    "class PyLifModel(PyLoihiProcessModel):\n",
    "    a_in: PyInPort = LavaPyType(PyInPort.VEC_DENSE, np.float)\n",
    "    s_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, bool, precision=1)\n",
    "    u: np.ndarray = LavaPyType(np.ndarray, np.float)\n",
    "    v: np.ndarray = LavaPyType(np.ndarray, np.float)\n",
    "    bias: np.ndarray = LavaPyType(np.ndarray, np.float)\n",
    "    du: float = LavaPyType(float, np.float)\n",
    "    dv: float = LavaPyType(float, np.float)\n",
    "    vth: float = LavaPyType(float, np.float)\n",
    "    spikes: np.ndarray = LavaPyType(np.ndarray, bool)\n",
    "\n",
    "    def run_spk(self):\n",
    "        a_in_data = self.a_in.recv()\n",
    "        self.u[:] = self.u * (1 - self.du)\n",
    "        self.u[:] += a_in_data\n",
    "        self.v[:] = self.v * (1 - self.dv) + self.u + self.bias\n",
    "        s_out = self.v >= self.vth\n",
    "        self.v[s_out] = 0  # Reset voltage to 0\n",
    "        # self.spikes = s_out\n",
    "        self.s_out.send(s_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639dc805",
   "metadata": {},
   "source": [
    "## Create a DenseLayer Hierarchical _Process_ that encompasses Dense and LIF _Process_ behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a6aa43",
   "metadata": {},
   "source": [
    "Now we create a DenseLayer _Hierarchical Process_ combining LIF neural _Processes_ and Dense connection _Processes_. Our _Hierarchical Process_ contains all of the variables (`u`, `v`, `bias`, `du`, `dv`, `vth`, and `s_out`) native to the LIF _Process_ plus the `weights` variable native to the Dense _Process_. The InPort to our _Hierarchical Process_ is `s_in`, which represents the spike inputs to our Dense synaptic connections. These Dense connections synapse onto a population of LIF neurons. The OutPort of our _Hierarchical Process_ is `s_out`, which represents the spikes output by the layer of LIF neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3035e530",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer(AbstractProcess):\n",
    "    \"\"\"Combines Dense and LIF Processes.\"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        shape = kwargs.get(\"shape\", (1, 1))\n",
    "        du = kwargs.pop(\"du\", 0)\n",
    "        dv = kwargs.pop(\"dv\", 0)\n",
    "        bias = kwargs.pop(\"bias\", 0)\n",
    "        bias_exp = kwargs.pop(\"bias_exp\", 0)\n",
    "        vth = kwargs.pop(\"vth\", 10)\n",
    "        weights = kwargs.pop(\"weights\", 0)\n",
    "\n",
    "        self.s_in = InPort(shape=(shape[1],))\n",
    "        # output of Dense synaptic connections is only used internally\n",
    "        # self.a_out = OutPort(shape=(shape[0],))\n",
    "        self.weights = Var(shape=shape, init=weights)\n",
    "        # input to LIF population from Dense synaptic connections is only used internally\n",
    "        # self.a_in = InPort(shape=(shape[0],))\n",
    "        self.s_out = OutPort(shape=(shape[0],))\n",
    "        self.u = Var(shape=(shape[0],), init=0)\n",
    "        self.v = Var(shape=(shape[0],), init=0)\n",
    "        self.bias = Var(shape=(shape[0],), init=bias)\n",
    "        self.du = Var(shape=(1,), init=du)\n",
    "        self.dv = Var(shape=(1,), init=dv)\n",
    "        self.vth = Var(shape=(1,), init=vth)\n",
    "        # self.spikes = Var(shape=(shape[0],), init=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd62de90",
   "metadata": {},
   "source": [
    "## Create a _SubProcessModel_ that implements the DenseLayer _Process_ using Dense and LIF child _Processes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ee227b",
   "metadata": {},
   "source": [
    "Now we will create the _SubProcessModel_ that implements our DenseLayer _Process_. This inherits from the _AbstractSubProcessModel_ class. Recall that _SubProcessModels_ also inherit the compute resource requirements from the _ProcessModels_ of their child _Processes_. In this example, we will use the LIF and Dense _ProcessModels_ requiring a CPU compute resource that were defined earlier in the tutorial,  and `SubDenseLayerModel` will therefore implicitly require the CPU compute resource. \n",
    "\n",
    "The `__init__()` constructor of `SubDenseLayerModel` builds the sub _Process_ structure of the `DenseLayer` _Process_. The `DenseLayer` _Process_ gets passed to the `__init__()` method via the `proc` attribute. The `__init__()` constructor first instantiates the child LIF and Dense _Processes_. Initial conditions of the `DenseLayer` _Process_, which are required to instantiate the child LIF and Dense _Processes_, are accessed through `proc.init_args`. \n",
    "\n",
    "We then `connect()` the in-port of the Dense child _Process_ to the in-port of the `DenseLayer` parent _Process_ and the out-port of the LIF child _Process_ to the out-port of the `DenseLayer` parent _Process_. Note that ports of the `DenseLayer` parent process are accessed using `proc.in_ports` or `proc.out_ports`, while ports of a child _Process_ like LIF are accessed using `self.lif.in_ports` and `self.lif.out_ports`. Our _ProcessModel_ also internally `connect()`s the out-port of the Dense connection child _Process_ to the in-port of the LIF neural child _Process_. \n",
    "\n",
    "The `alias()` method exposes the variables of the LIF and Dense child _Processes_ to the `DenseLayer` parent _Process_. Note that the variables of the `DenseLayer` parent _Process_ are accessed using `proc.vars`, while the variables of a child _Process_ like LIF are accessed using `self.lif.vars`. Note that unlike a _LeafProcessModel_, a _SubProcessModel_ does not require variables to be initialized with a specified data type or precision. This is because the data types and precisions of all `DenseLayer` _Process_ variables (`proc.vars`) are determined by the particular _ProcessModels_ chosen by the Run Configuration to implement the LIF and Dense child _Processes_. This allows the same _SubProcessModel_ to be used flexibly across multiple languages and compute resources when the child _Processes_ have multiple _ProcessModel_ implementations. _SubProcessModels_ thus enable the composition of complex applications agnostic of platform-specific implementations. In this example, we will implement the LIF and Dense _Processes_ with the _PyLoihiProcessModels_ defined earlier in the tutorial, so the `DenseLayer` variables aliased from LIF and Dense implicity have type `LavaPyType` and precisions as specified in `PyLifModel` and `PyDenseModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddd9daba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from lava.proc.lif.process import LIF\n",
    "from lava.proc.dense.process import Dense\n",
    "from lava.magma.core.model.sub.model import AbstractSubProcessModel\n",
    "\n",
    "from lava.magma.core.sync.protocols.loihi_protocol import LoihiProtocol\n",
    "from lava.magma.core.decorator import implements\n",
    "\n",
    "\n",
    "@implements(proc=DenseLayer, protocol=LoihiProtocol)\n",
    "class SubDenseLayerModel(AbstractSubProcessModel):\n",
    "    def __init__(self, proc):\n",
    "        \"\"\"Builds sub Process structure of the Process.\"\"\"\n",
    "        # Instantiate child processes\n",
    "        # input shape is a 2D vec (shape of weight mat)\n",
    "        shape = proc.init_args.get(\"shape\", (1, 1))\n",
    "        weights = proc.init_args.get(\"weights\", (1, 1))\n",
    "        bias = proc.init_args.get(\"bias\", (1, 1))\n",
    "        vth = proc.init_args.get(\"vth\", (1, 1))\n",
    "        # shape is a 2D vec (shape of weight mat)\n",
    "        self.dense = Dense(shape=shape, weights=weights)\n",
    "        # shape is a 1D vec\n",
    "        self.lif = LIF(shape=(shape[0],), bias=bias, vth=vth)\n",
    "        # connect Parent in port to child Dense in port\n",
    "        proc.in_ports.s_in.connect(self.dense.in_ports.s_in)\n",
    "        # connect Dense Proc out port to LIF Proc in port\n",
    "        self.dense.out_ports.a_out.connect(self.lif.in_ports.a_in)\n",
    "        # connect child LIF out port to parent out port\n",
    "        self.lif.out_ports.s_out.connect(proc.out_ports.s_out)\n",
    "\n",
    "        proc.vars.u.alias(self.lif.vars.u)\n",
    "        proc.vars.v.alias(self.lif.vars.v)\n",
    "        proc.vars.bias.alias(self.lif.vars.bias)\n",
    "        proc.vars.du.alias(self.lif.vars.du)\n",
    "        proc.vars.dv.alias(self.lif.vars.dv)\n",
    "        proc.vars.vth.alias(self.lif.vars.vth)\n",
    "        proc.vars.weights.alias(self.dense.vars.weights)\n",
    "        # proc.vars.spikes.alias(self.lif.vars.spikes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e38afa1",
   "metadata": {},
   "source": [
    "## Run the DenseLayer _Process_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763a4881-0e8d-4d0a-84c4-c2bde204247a",
   "metadata": {},
   "source": [
    "#### Run Connected DenseLayer _Processes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "657dc72a-4507-4db4-8364-a4be54779bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 weights: \n",
      " [[0. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 0.]] \n",
      "\n",
      "\n",
      " ----- \n",
      "\n",
      "t:  0\n",
      "Layer 0 v:  [4. 4. 4.]\n",
      "Layer 1 u:  [0. 0. 0.]\n",
      "Layer 1 v:  [4. 4. 4.]\n",
      "\n",
      " ----- \n",
      "\n",
      "t:  1\n",
      "Layer 0 v:  [8. 8. 8.]\n",
      "Layer 1 u:  [0. 0. 0.]\n",
      "Layer 1 v:  [8. 8. 8.]\n",
      "\n",
      " ----- \n",
      "\n",
      "t:  2\n",
      "Layer 0 v:  [0. 0. 0.]\n",
      "Layer 1 u:  [0. 0. 0.]\n",
      "Layer 1 v:  [0. 0. 0.]\n",
      "\n",
      " ----- \n",
      "\n",
      "t:  3\n",
      "Layer 0 v:  [4. 4. 4.]\n",
      "Layer 1 u:  [0. 1. 0.]\n",
      "Layer 1 v:  [4. 5. 4.]\n",
      "\n",
      " ----- \n",
      "\n",
      "t:  4\n",
      "Layer 0 v:  [8. 8. 8.]\n",
      "Layer 1 u:  [0. 1. 0.]\n",
      "Layer 1 v:  [ 8. 10.  8.]\n",
      "\n",
      " ----- \n",
      "\n",
      "t:  5\n",
      "Layer 0 v:  [0. 0. 0.]\n",
      "Layer 1 u:  [0. 1. 0.]\n",
      "Layer 1 v:  [0. 0. 0.]\n",
      "\n",
      " ----- \n",
      "\n",
      "t:  6\n",
      "Layer 0 v:  [4. 4. 4.]\n",
      "Layer 1 u:  [0. 2. 0.]\n",
      "Layer 1 v:  [4. 6. 4.]\n",
      "\n",
      " ----- \n",
      "\n",
      "t:  7\n",
      "Layer 0 v:  [8. 8. 8.]\n",
      "Layer 1 u:  [0. 2. 0.]\n",
      "Layer 1 v:  [8. 0. 8.]\n",
      "\n",
      " ----- \n",
      "\n",
      "t:  8\n",
      "Layer 0 v:  [0. 0. 0.]\n",
      "Layer 1 u:  [0. 2. 0.]\n",
      "Layer 1 v:  [0. 6. 0.]\n",
      "\n",
      " ----- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lava.magma.core.run_configs import RunConfig, Loihi1SimCfg\n",
    "from lava.magma.core.run_conditions import RunSteps\n",
    "\n",
    "dim = (3, 3)\n",
    "# shape=dim\n",
    "# set targeted weight mat\n",
    "weights0 = np.zeros(shape=dim)\n",
    "weights0[1, 1] = 1\n",
    "weights1 = weights0\n",
    "# instantiate 2 DenseLayers\n",
    "layer0 = DenseLayer(shape=dim, weights=weights0, bias=4, vth=10)\n",
    "layer1 = DenseLayer(shape=dim, weights=weights1, bias=4, vth=10)\n",
    "# connect layer 0 to layer 1\n",
    "layer0.s_out.connect(layer1.s_in)\n",
    "\n",
    "print(\"Layer 1 weights: \\n\", layer1.weights.get(), \"\\n\")\n",
    "print(\"\\n ----- \\n\")\n",
    "\n",
    "rcfg = Loihi1SimCfg(select_tag=\"floating_pt\", select_sub_proc_model=True)\n",
    "\n",
    "for t in range(9):\n",
    "    # running layer 1 runs all connected layers (layer 0)\n",
    "    layer1.run(condition=RunSteps(num_steps=1), run_cfg=rcfg)\n",
    "    print(\"t: \", t)\n",
    "    print(\"Layer 0 v: \", layer0.v.get())\n",
    "    print(\"Layer 1 u: \", layer1.u.get())\n",
    "    print(\"Layer 1 v: \", layer1.v.get())\n",
    "    # print('Layer 1 spikes: ', layer1.spikes.get())\n",
    "    print(\"\\n ----- \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7349aa-56cf-4759-9af2-15bebd63e399",
   "metadata": {},
   "source": [
    "## How to learn more?\n",
    "\n",
    "If you want to find out more about _SubProcessModels_, have a look at the [Lava documentation](https://lava-nc.org/) or dive into the [source code](https://github.com/lava-nc/lava/tree/main/src/lava/magma/core/model/sub/model.py).\n",
    "\n",
    "To receive regular updates on the latest developments and releases of the Lava Software Framework please subscribe to [our newsletter](http://eepurl.com/hJCyhb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
